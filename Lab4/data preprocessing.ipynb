{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reikalingos bibliotekos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagalbinės funkcijos reikalingos atidaryti CIFAR duomenų failui ir išsaugoti nuotraukoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(filepath):\n",
    "    with open(filepath, 'rb') as file:\n",
    "        dict = pickle.load(file, encoding=\"bytes\")\n",
    "    return dict\n",
    "\n",
    "def makedir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def create_data_directories(output_dir, label_names):\n",
    "    makedir(output_dir)\n",
    "    makedir(os.path.join(output_dir, \"train\"))\n",
    "    makedir(os.path.join(output_dir, \"valid\"))\n",
    "    \n",
    "    for label_name in label_names:\n",
    "        makedir(os.path.join(output_dir, \"train\", label_name))\n",
    "        makedir(os.path.join(output_dir, \"valid\", label_name))\n",
    "        \n",
    "def get_save_path(output_dir, train_or_valid, label_name, filename):\n",
    "    filename_without_extension, _ = os.path.splitext(filename)\n",
    "    filename = filename_without_extension + \".jpg\"\n",
    "    return os.path.join(output_dir, train_or_valid, label_name, filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR duomenų masyvo transponavimas ir išsaugojimas į nuotraukas\n",
    "\n",
    "`train_split`, `seed`, ir `output_dir` gali būt keičiami. `seed` nurodome, kad galėtume atkartoti identišką duomenų išmaišmą."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# 0.7 indicates that 70% of data will go to the training set & 30$ to the validation set.\n",
    "train_split= 0.7\n",
    "seed = 1\n",
    "output_dir= \"data/\"\n",
    "\n",
    "\n",
    "with open(\"./cifar-10-batches-py/batches.meta.txt\") as file:\n",
    "    label_names = [line.rstrip() for line in file]\n",
    "\n",
    "\n",
    "data_filepaths = glob.glob(\"./cifar-10-batches-py/*_batch*\")\n",
    "data_filepaths.sort()\n",
    "\n",
    "train_and_test_data = []\n",
    "\n",
    "for filepath in data_filepaths:\n",
    "    dict = unpickle(filepath)\n",
    "    images = dict[b\"data\"]\n",
    "    label_ids = dict[b\"labels\"]\n",
    "    filenames = [str(filename, \"UTF-8\") for filename in dict[b\"filenames\"]]\n",
    "    \n",
    "    for image, id, filename in zip(images, label_ids, filenames):\n",
    "        train_and_test_data.append((image, label_names[id], filename))\n",
    "\n",
    "create_data_directories(output_dir, label_names)\n",
    "\n",
    "random.Random(seed).shuffle(train_and_test_data)\n",
    "\n",
    "train_last_id = int(len(train_and_test_data) * train_split)\n",
    "\n",
    "for (image, label_name, filename) in train_and_test_data[ : train_last_id]:\n",
    "    image = np.transpose(np.reshape(image, (3, 32, 32)), (1,2,0))\n",
    "    Image.fromarray(image, mode=\"RGB\").save(get_save_path(output_dir, \"train\", label_name, filename))\n",
    "\n",
    "for (image, label_name, filename) in train_and_test_data[train_last_id : ]:\n",
    "    image = np.transpose(np.reshape(image, (3, 32, 32)), (1,2,0))\n",
    "    Image.fromarray(image, mode=\"RGB\").save(get_save_path(output_dir, \"valid\", label_name, filename))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
