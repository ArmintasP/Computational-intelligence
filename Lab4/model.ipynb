{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reikiamos bibliotekos ir GPU resursų naudojimo pasirinkimas (jei nėra - naudojama CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import graph as MyGraph\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "num_workers = 2 if torch.cuda.is_available() else 0\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esminė treniravimo funkcija ir tikslumo skaičiavimo funkcija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(optimizer, loss_func, model, loader):\n",
    "    losses = np.array([], dtype = np.float32)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for data in loader:\n",
    "        # Some manipulation, to make it work on any device.\n",
    "        images = data[0].to(device)\n",
    "        labels = torch.nn.functional.one_hot(data[1], model.num_classes).float().to(device) \n",
    "        \n",
    "        # Getting predictions.\n",
    "        pred = model(images)\n",
    "        loss = loss_func(pred, labels)\n",
    "        losses = np.append(losses, loss.cpu().detach().numpy()) \n",
    "        \n",
    "        # Compute the gradient, change values of weights and reset grad to zero for parameters.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for data in loader:\n",
    "        images = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "\n",
    "        # Enabling no_grad makes it a bit faster.\n",
    "        with torch.no_grad():\n",
    "          pred = model(images)\n",
    "        label_pred = torch.argmax(pred, axis = 1)\n",
    "\n",
    "        correct_count += torch.sum(labels == label_pred)\n",
    "        total_count += images.shape[0]\n",
    "    \n",
    "    return correct_count / total_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treniravimas ir einamojo duomenų rinkinio tikslumo įvertinimas\n",
    "\n",
    "`Graph` klasė aprašyta `graph.py` faile. Iškelta, nes ten tik grafikų braižymo klasė, kuri užima daug vietos (vizualiai).\n",
    "\n",
    "Optimizatorių ir nuostolių funkciją galima keisti būtent čia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model, loader_train, loader_valid, epoch_count, lr, loss_func, optimizer):\n",
    "    optimizer = optimizer(model.parameters(), lr)\n",
    "\n",
    "    graph = MyGraph.Graph()\n",
    "\n",
    "    for epoch in range(1, epoch_count + 1):\n",
    "        loss = train_epoch(optimizer, loss_func, model, loader_train) \n",
    "        \n",
    "        train_accuracy = evaluate(model, loader_train)\n",
    "        valid_accuracy = evaluate(model, loader_valid)    \n",
    "        \n",
    "        print(f'[{epoch}] Train Acc: {train_accuracy}.2f  Valid Acc: {valid_accuracy}.2f') \n",
    "        \n",
    "        # Pass accuracies and loss values to graph drawing function.\n",
    "        graph.draw_graphs(epoch, train_accuracy.cpu().item(), loss, train= True)\n",
    "        graph.draw_graphs(epoch, valid_accuracy.cpu().item(), None, train= False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet modelis, tik vietoj sigmoidinių aktv. funkcijos naudota ELU.\n",
    "Paimta iš: https://d2l.ai/chapter_convolutional-neural-networks/lenet.html\n",
    "\n",
    "Dropout taikomas priešpaskutiniam sluoksniui, t. y. atsitktinai pagal nurodytą tikimybė paskutinio sluoksnio neuronai negaus išeičių iš priešpriešpaskutinio sluoksnio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelA(nn.Module): \n",
    "    def __init__(self, num_classes, dropout_prob):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(120), nn.ELU(),\n",
    "            nn.Dropout(p = dropout_prob), nn.LazyLinear(84), nn.ELU(),\n",
    "            nn.LazyLinear(num_classes))\n",
    "    \n",
    "    \n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    \n",
    "class ModelB(nn.Module): \n",
    "    def __init__(self, num_classes, dropout_prob):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=7), nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(100), nn.ELU(),\n",
    "            nn.LazyLinear(50), nn.ELU(),\n",
    "            nn.Dropout(p = dropout_prob), nn.LazyLinear(25), nn.ELU(),\n",
    "            nn.LazyLinear(num_classes))\n",
    "    \n",
    "    \n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    \n",
    "class ModelC(nn.Module): \n",
    "    def __init__(self, num_classes, dropout_prob):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(8, kernel_size=3), nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            nn.LazyConv2d(16, kernel_size=3), nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(80), nn.ELU(),\n",
    "            nn.Dropout(p = dropout_prob), nn.LazyLinear(24), nn.ELU(),\n",
    "            nn.LazyLinear(num_classes))\n",
    "    \n",
    "    \n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentacijos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_w = 32\n",
    "image_h = 32\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ColorJitter(brightness = 0.4, saturation = 0.1, hue = 0.1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomGrayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data\"\n",
    "batch_size = 1\n",
    "dropout_prob = 0.4\n",
    "num_classes = 10\n",
    "optimizer = lambda x, l : torch.optim.SGD(x, lr = l)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "epoch_count = 10\n",
    "\n",
    "# 1 x 3 x 32 x 32 (we are going to use 3-channel pictures with 32 width and 32 height)\n",
    "image_dimension = [1, 3, image_w, image_h]\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(f'{directory}/train', transform= train_transforms)\n",
    "val_dataset = torchvision.datasets.ImageFolder(f'{directory}/valid', transform= val_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = False)\n",
    "\n",
    "\n",
    "model = ModelA(dropout_prob = dropout_prob, num_classes= num_classes).to('cpu')\n",
    "\n",
    "print('Structure:\\n')\n",
    "model.layer_summary(image_dimension)\n",
    "print(f'Parameter count: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "start = time.time()\n",
    "train_and_eval(model, train_loader, val_loader, epoch_count = epoch_count, lr = lr, loss_func=loss_func, optimizer=optimizer)\n",
    "end = time.time()\n",
    "\n",
    "print('Time elapsed:', (end - start)/60, \" minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"models/C.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsitikų skaičiavimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "classes = {}\n",
    "for class_name, class_id in val_dataset.class_to_idx.items():\n",
    "    classes[class_id] = class_name\n",
    "  \n",
    "matrix = []\n",
    "for _ in classes:\n",
    "    matrix.append([0 for _ in classes])\n",
    "\n",
    "\n",
    "# Speeds up computations.\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch, labels in val_loader:\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        predictions = model(batch)\n",
    "        \n",
    "        for i in range(len(predictions)):\n",
    "            predicted_class = torch.argmax(predictions[i])\n",
    "\n",
    "            if (labels[i] == predicted_class):\n",
    "                matrix[predicted_class][predicted_class] += 1\n",
    "            else:\n",
    "                matrix[labels[i]][predicted_class] += 1\n",
    "\n",
    "\n",
    "\n",
    "columns = [classes[class_id] for class_id in classes]\n",
    "dataframe = pd.DataFrame(matrix, columns=columns, index=columns)  \n",
    "\n",
    "dataframe = pd.concat(\n",
    "    [pd.concat(\n",
    "        [dataframe],\n",
    "        keys=['Predicted Class'], axis=1)],\n",
    "    keys=['Actual Class']\n",
    ")\n",
    "\n",
    "print(dataframe, '\\n\\n')\n",
    "\n",
    "\n",
    "## Printing statistics.\n",
    "for class_id in classes:\n",
    "    TP = matrix[class_id][class_id]\n",
    "    FN = sum(matrix[class_id]) - TP\n",
    "    FP = sum([sublist[class_id] for sublist in matrix]) - TP\n",
    "    TN = sum(sum(matrix,[])) - TP - FN - FP\n",
    "\n",
    "    metrics = {}\n",
    "    metrics['accuracy'] = (TP + TN) / (TP + FP + TN + FN)\n",
    "    metrics['recall'] = TP / (TP + FN)\n",
    "    metrics['precision'] = TP / (TP + FP)\n",
    "    metrics['f1'] = 2 * (metrics['precision'] * metrics['recall']) / (metrics['precision'] + metrics['recall'])\n",
    "\n",
    "    metrics = {k: round(v, 2) for k, v in metrics.items()}\n",
    "\n",
    "    # print(TP, FN, FP, TN)\n",
    "    print(classes[class_id], ':', metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_30_set = torchvision.datasets.ImageFolder(f'30_test_images/', transform= val_transforms)\n",
    "test_images_30_loader = torch.utils.data.DataLoader(test_images_30_set, batch_size = batch_size, num_workers = num_workers, shuffle = False)\n",
    "\n",
    "\n",
    "classes = {}\n",
    "for class_name, class_id in test_images_30_set.class_to_idx.items():\n",
    "    classes[class_id] = class_name\n",
    "  \n",
    "# Speeds up computations.\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    print('Actual\\t\\t\\tPredicted')\n",
    "    for batch, labels in test_images_30_loader:\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        predictions = model(batch)\n",
    "        \n",
    "        for i in range(len(predictions)):\n",
    "            predicted_class = torch.argmax(predictions[i]).item()\n",
    "            \n",
    "            print(classes[labels[i].item()] + \"\\t\\t\\t\" + classes[predicted_class])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
